---
title: "Two Proportions by Bayes"
author: 
  - Denise Welsch
  - Contributors^[Students Names]
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
#bibliography: ["references.bib"]
classoption: landscape
params:
  data: NA
  filename: NA
  fencoding: NA # used in Shiny app 
  decimal: NA
  enc_guessed: NA # used in Shiny app 
  level: NA
  outcome: NA
  exposure: NA 
  s1: NA 
  n1: NA 
  s2: NA 
  n2: NA
  a1: NA
  b1: NA
  a2: NA
  b2: NA
  user_selection_function_param: NA
  rope_user: NA
header-includes:
   - \usepackage{xcolor}
#   - \setmainfont[BoldFont=FiraSans-Bold, Extension=.otf]{FiraSans-Regular}
   - \usepackage{booktabs}
   - \usepackage{longtable}
   - \usepackage{float}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment='', message = FALSE, error = TRUE, warning=FALSE, fig.width=8)

# Import libraries used further below
library(knitr) # for tables
library(kableExtra) # for tables 
library(plotly) # for 3d plots
library(bayestestR)
library(LearnBayes)
```


```{r chunksinit}
# Initialize evaluation resp. execution of subsequent chunks
## Evaluation only for file upload
evalfile <- is.data.frame(params$data)
## Evaluation for cell frequency upload 
eval <- !is.na(params$s1)
## Other 
evalbasic_file <- FALSE
eval_rows <- FALSE
```


```{r getdatafile, eval = evalfile}

# Get data as a file 
tryCatch({
  
  # Get data
  df <- params$data
  
  # Save a copy for other purposes (downloadable code) 
  df_code <- df
  
  # Restrict to exposure and outcome
  vars <- c(params$outcome, params$exposure)
  df <- df[,vars,drop=FALSE]
  
  # Drop empty rows
  rowsums <- data.frame(sapply(df,is.na))
  if (length(which(rowSums(rowsums) == dim(df)[2])) != 0L){
    eval_rows <- TRUE
    rows_drop <- (which(rowSums(rowsums) == dim(df)[2]))
    length_non_complete <- length(which(rowSums(rowsums) == dim(df)[2]))
    df <- df[-rows_drop, ,drop=FALSE]
  }
  
  # Initialize next computations
  eval <- TRUE
  
  # Move on if file upload and successful current chunk 
  evalbasic_file <- as.logical(evalfile*eval)

}, error=function(e) {
  
  stop(safeError("Could not get the file data. "))
})



```

```{r freqfromfile, results="asis", eval=evalbasic_file}
# Compute cell frequencies from dataframe 
# Use s1,n1,s2,n2 for the names 
```

\pagebreak

```{r guititle, results="asis", eval=eval}
cat("# User Selection", fill=TRUE)
```

```{r guifile, results="asis", eval=evalbasic_file}
# Basic information for the case file upload
cat("Automatic statistics for the file:", fill=TRUE)
dataname <- params$filename[1]
kable(dataname, col.names = "File", linesep = '', longtable=T) 

cat("Your selection for the encoding:", fill=TRUE)
if (params$fencoding=="unknown"){
  cat("Auto")
} else {cat("UTF-8")}
cat("\\newline",fill=TRUE) 

cat("Your selection for the decimal character:", fill=TRUE)
if (params$decimal=="auto"){
  cat("Auto")
} else {cat(params$decimal)}
cat("\\newline",fill=TRUE) 
  
cat("Observations (rows with at least one non-missing value): ", fill=TRUE)
cat(dim(df)[1])
cat("\\newline",fill=TRUE) 

# Missing rows
if (exists("length_non_complete")){
  cat("Number of rows that are dropped because they contain no values (all values are missing):", length_non_complete)
  cat("\\newline",fill=TRUE) 
}

if (exists("vars")){
  cat("Name of the Outcome Variable: ", params$outcome, fill=TRUE)
  cat("\\newline",fill=TRUE) 
}

if (exists("vars")){
  cat("Name of the Exposure Variable: ", params$exposure, fill=TRUE)
}
```


```{r cellupload, eval=!evalfile, results='asis'}
# Upload as cell frequencies, display them nicely
cat(s1)
cat(n1)
cat(s2)
cat(n2)
```


```{r guirest, eval=eval, results='asis'}
# display in the report the rest of the information arising from the GUI (e.g. priors, function of parameters etc.)
```

\pagebreak

```{r title_preamble, eval=eval, results='asis'}
cat("# Preamble", fill=TRUE)
# Why Bayesian. Explain what benefits will be gleaned by a Bayesian analysis (as opposed to a frequentist analysis).
# Goals of analysis. Explain the goals of the analysis. This prepares the audience for the type of models to expect and how the results will be described. 
# Check references: Kruschke, John K., Bayesian Analysis Reporting Guidelines, Nature Human Behaviour, 2021
```

```{r title_descstats, eval=eval, results='asis'}
cat("# Descriptive Statistics and Plots", fill=TRUE)
```

```{r datahead, eval=evalbasic_file, results='asis'}
cat("## Data Head (first five observations)", fill=TRUE)
knitr::kable(head(df), col.names = c("Outcome", "Exposure"), linesep = '', longtable=T) %>%
  kable_styling(font_size = 8, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))
```

```{r desctable, eval=eval, dev="cairo_pdf"}
cat("## Frequency Table", fill=TRUE)
# Insert a frequency table for the data
```

```{r descplots, eval=eval, dev="cairo_pdf"}
cat("## Barplots", fill=TRUE)
# Insert beautiful descriptive plots suitable for our dataset, e.g. barplots 
```

```{r the_model, eval=eval, results='asis'}
cat("# The Model", fill=TRUE)
# insert latex equations for the model 
```

```{r likelihoodtext, eval=eval, results='asis'}
cat("## The Likelihood", fill=TRUE)
# Explain the likelihood function and all the parameters
```

```{r likelihoodplot, eval=eval, results='asis'}
# Plot the likelihood (follow second row from page 167 DDBA)
# Consider the range for Theta1 and Theta2 defined above 
```

```{r priortext, eval=eval, results='asis'}
cat("## The Prior", fill=TRUE)
# if the default is used, explain and justify the prior distribution of the parameters in the model.
# otherwise, specify that it is user defined
```

```{r priorplot, eval=eval, results='asis'}
# Plot the prior (follow first row from page 167 DDBA)

## Range for plotting
Theta1 = seq(0.001, 0.999, by=0.001) 
Theta2 = seq(0.001, 0.999, by=0.001) 

## Priors for plotting 
pTheta1 = dbeta(Theta1,a1,b1)
pTheta2 = dbeta(Theta2,a2,b2) 
```

```{r priorcheck, eval=eval, results='asis'}
# Prior predictive check. Especially when using informed priors but even with broad priors, it is valuable to report a prior predictive check to demonstrate that the prior really generates simulated data consistent with the assumed prior knowledge.
# References: Jim Albert page 31, plots similar to BARG-Supplement 6.1.2
```

```{r posterior_text, eval=eval, results='asis'}
cat("# The Posterior", fill=TRUE)
# Describe the posterior distribution
```

```{r posterior_plot, eval=eval, dev="cairo_pdf"}
# Posterior for plotting (follow last row from page 167 DDBA)
pTheta1Theta2GivenData <- matrix(data=NA, nrow=length(Theta1), ncol=length(Theta2))
for (i in 1:length(Theta1)){
  for (j in 1:length(Theta2)){
    pTheta1Theta2GivenData[i,j]<- dbeta(Theta1[i], a1+s1, b1+n1-s1)*dbeta(Theta2[j], a2+s2, b2+n2-s2)   
  }
} 

# Generate and include plots, export as a png and include or find another solution 
plot_ly(x = Theta1, y = Theta2, z = pTheta1Theta2GivenData, type = "surface") 
```

```{r posterior_check, eval=eval, dev="cairo_pdf"}
# Posterior predictive check. Provide a posterior predictive check to show that the model usefully mimics the data.
```

```{r simulate, eval=eval}
## Simulate from posterior
posterior_Theta1 <- rbeta(10000,s1+a1,(n1-s1)+b1)
posterior_Theta2 <- rbeta(10000,s2+a2,(n2-s2)+b2)
```

```{r functionparameter, eval=eval}
## Function of parameters of interest
if (user_selection_function_param == 3) {
  estimate <- 1-posterior_Theta1/posterior_Theta2
} else if (user_selection_function_param == 2){
  estimate <- posterior_Theta1/posterior_Theta2  
} else {
  estimate <- posterior_Theta1-posterior_Theta2  
}
```

```{r describe_posterior, eval=eval}
# Describe posterior in a table 
# Summarize posterior of variables. For continuous parameters, derived variables and predicted values, report the central tendency and limits of the credible interval. Explicitly state whether you are using density-based values (mode and HDI) or quantile-based values (median and ETI), and state the mass of the credible interval (for example, 95%)
if (is.null(rope_user)==TRUE){
  describe_posterior(estimate, ci = 0.95, centrality="all", dispersion=TRUE, test=NULL)
} else {
  describe_posterior(estimate, ci = 0.95, centrality="all", dispersion=TRUE, test="rope", rope_range = rope_user)
}
```

```{r plot_hdi, eval=eval}
## Display graphical posterior information
### Use bayestestR package 
plot(hdi(estimate, ci = c(.89, .95, .99)))
```

```{r plot_eti, eval=eval}
## Display graphical posterior information
### Use bayestestR package 
plot(eti(estimate))
```

```{r plotpost, eval=eval}
# Use the plotPost function (page 205 Kruschke)
```

```{r plotboth, eval=eval}
# Plot both in percent
Theta1pct <- posterior_Theta1*100
Theta2pct <- posterior_Theta2*100
results <- data.frame(Theta1pct,Theta2pct)
results %>%
  tidyr::pivot_longer(everything(), names_to = "group") %>%
  ggplot(aes(x = value, fill = group)) +
  ggdist::stat_halfeye(.width = c(0.89, 0.95),
                       alpha = .8,
                       slab_colour = "black",
                       slab_size = .5) +
  ggtitle("xxx") +
  xlab("xlael") +
  scale_x_continuous(labels = scales::label_percent(scale = 1),
                     breaks = seq.int(0, 1, .1)) +
  theme(axis.title.y = element_blank(),
        axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.grid.major.y = element_blank(),
        panel.grid.minor.y = element_blank())
```

```{r decision, eval=eval}
# ROPE limits. If using a continuous-parameter posterior distribution as the basis for decision, state and justify the limits of the ROPE and the required probability mass.
```