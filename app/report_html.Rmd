---
title: "Two Proportions by Bayes"
author: 
  - Denise Welsch
  - Contributors^[Theresa Binot, Viktoria Daum, Renée Defren, Chiara Freitag, Jule Grote, Konrad Junkes, Anna-Lena Künster, Jomana Reusch, Simone Schüttler]
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_document:
    toc: true
    toc_depth: 2
#bibliography: ["references.bib"]
classoption: landscape
params:
  data: NA
  filename: NA
  enc_guessed: NA # used in Shiny app 
  presence_exposure: NA
  presence_outcome: NA
  exposure: NA
  outcome: NA
  n_exposure1_outcome1: NA 
  n_exposure1: NA 
  n_exposure0_outcome1: NA 
  n_exposure0: NA
  a1: NA
  b1: NA
  a2: NA
  b2: NA
  user_selection_function_param: NA
  rope_user: NA
header-includes:
   - \usepackage{xcolor}
   - \usepackage{booktabs}
   - \usepackage{longtable}
   - \usepackage{float}
   - \usepackage{amsmath}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment='', message = FALSE, error = TRUE, warning=FALSE, fig.width=8)

# Import libraries used further below
library(knitr) # for tables
library(kableExtra) # for tables 
library(plotly) # for 3d plots
library(bayestestR)
library(LearnBayes)

```


```{r chunksinit}
# Initialize evaluation resp. execution of subsequent chunks
## Evaluation only for file upload
evalfile <- is.data.frame(params$data)
## Evaluation for cell frequency upload 
evalcellfreq  <- !is.na(params$n_exposure1_outcome1)
## Other initializations
evalfile2 <- FALSE
eval_rows <- FALSE
eval_final <- FALSE
rope_user <- NULL
```


```{r getdatafile, eval = evalfile}
# Get data as a file 
tryCatch({
  
  # Get data
  df <- params$data
  
  # Save a copy for other purposes (downloadable code) 
  df_code <- df
  
  # Restrict to exposure and outcome
  vars <- c(params$outcome, params$exposure)
  df <- df[,vars,drop=FALSE]
  
  # Drop empty rows
  rowsums <- data.frame(sapply(df,is.na))
  if (length(which(rowSums(rowsums) == dim(df)[2])) != 0L){
    eval_rows <- TRUE
    rows_drop <- (which(rowSums(rowsums) == dim(df)[2]))
    length_non_complete <- length(which(rowSums(rowsums) == dim(df)[2]))
    df <- df[-rows_drop, ,drop=FALSE]
  }
  
  # frequencies are called n_
  # for example n_exposure0_outcome1 is the frequency of datapoints without exposure but with present outcome
  n_exposure1_outcome1 = sum(df[params$outcome]==params$presence_outcome & df[params$exposure]==params$presence_exposure) #s1
  n_exposure0_outcome1 = sum(df[params$outcome]== params$presence_outcome & df[params$exposure]!=params$presence_exposure) #s2
  
  n_exposure1 = sum(df[params$exposure]==params$presence_exposure) #n1
  n_exposure0 = sum(df[params$exposure]!=params$presence_exposure) #n2
  
  # Initialize next computations
  evalfile2 <- TRUE
  
  # Move on if file upload and successful current chunk 
  eval_final <- as.logical(evalfile*evalfile2)
  
  # Set cell freq upload to false 
  evalcellfreq <- FALSE 

}, error=function(e) {
  
  stop(safeError("Could not get the file data. "))
})

```

```{r getcellfreq, eval=evalcellfreq}
n_exposure1_outcome1 = params$n_exposure1_outcome1
n_exposure1 = params$n_exposure1
n_exposure0_outcome1 = params$n_exposure0_outcome1
n_exposure0 = params$n_exposure0

eval_final = TRUE
```

```{r getprior, eval=eval_final}
# all these variables are in params for the two different data inputs
user_selection_function_param = params$user_selection_function_param
a1 = params$a1
a2 = params$a2
b1 = params$b1
b2 = params$b2

```


\pagebreak

```{r guititle, results="asis", eval=eval_final}
cat("# Basic Information", fill=TRUE)
```


```{r guifile, results="asis", eval=evalfile}
# Basic information for the case file upload
cat("Automatic statistics for the file:", as.character(params$filename[1]), fill=TRUE)
cat("<br>",fill=TRUE) 
  
cat("Observations (rows with at least one non-missing value): ", fill=TRUE)
cat(dim(df)[1])
cat("<br>",fill=TRUE) 

# Missing rows
if (exists("length_non_complete")){
  cat("Number of rows that are dropped because they contain no values (all values are missing):", length_non_complete)
  cat("<br>",fill=TRUE) 
}

if (exists("vars")){
  cat("Name of the Outcome Variable: ", params$outcome, fill=TRUE)
  cat("<br>",fill=TRUE) 
}

if (exists("vars")){
  cat("Name of the Exposure Variable: ", params$exposure, fill=TRUE)
}
```


```{r cellupload, eval=evalcellfreq , results='asis'}
# Upload as cell frequencies, display them nicely
cat(paste0("Number of Observations with both a present Outcome and a present Exposure: $y_1=", params$n_exposure1_outcome1,"$"), fill=TRUE)
cat("<br>",fill=TRUE) 
cat(paste0("Number of Observations with present Exposure: $n_1=",params$n_exposure1,"$"), fill=TRUE)
cat("<br>",fill=TRUE) 
cat(paste0("Number of Observations with present Outcome but without Exposure: $y_2=",params$n_exposure0_outcome1,"$"), fill=TRUE)
cat("<br>",fill=TRUE) 
cat(paste0("Number of Observations without Exposure: $n_2=",params$n_exposure0,"$"),fill=TRUE)
cat("<br>",fill=TRUE) 
cat("Name of the Outcome Variable: ", params$outcome, fill=TRUE)
cat("<br>",fill=TRUE) 
cat("Name of the Exposure Variable: ", params$exposure, fill=TRUE)
```


```{r guirest, eval=eval_final, results='asis'}
# display in the Basic Information the rest of the information arising from the GUI (e.g. priors, function of parameters etc.)
```

\pagebreak

```{r preamble, eval=eval_final, results='asis'}
cat("# Goals of the Analysis", fill=TRUE)
cat("The data is analyzed in this app by means of Baysian data analysis. Baysian data analysis is a branch of statistical data analysis based on two fundamental ideas: The first idea is that Baysian inference is a reallocation of credibility across possibilities, by means of the well known Bayes' theorem. The second idea is that the possibilities, over which we allocate credibility are parameter values in a meaningful mathematical model.", fill=TRUE)
cat("<br>",fill=TRUE) 
cat("<br>",fill=TRUE) 
cat("In Bayes' theorem, an existing knowledge about the parameter(s) under investigation (the a priori distribution, or prior for short) is combined with the new knowledge from the data ('likelihood'), resulting in a new, improved knowledge (a posteriori probability distribution).", fill=TRUE)
cat("<br>",fill=TRUE) 
cat("<br>",fill=TRUE) 
cat("An important benefit of Bayesian analysis is the ability to generate estimates and credible intervals for any derived parameter. Differences, ratios, effect sizes and novel parameter combinations are directly computed from the posterior distribution. Another benefit of Bayesian analysis are computationally robust estimates of parameter values and their credible intervals. The credible intervals do not depend on large-N approximations (as confidence intervals often do in frequentist approaches), nor do credible intervals depend on which tests are intended (as confidence intervals do in frequentist approaches).' (Kruschke, John K., Bayesian Analysis Reporting Guidelines, Nature Human Behaviour, 2021)", fill=TRUE)
cat("<br>",fill=TRUE) 
cat("<br>",fill=TRUE) 
cat("The goal of this app is to generate Bayes estimates and credible intervals for the user selected function of parameters: ", fill=TRUE)
if (params$user_selection_function_param==1) {
  cat("$\\theta_1 - \\theta_2$", fill=TRUE)
} else if (params$user_selection_function_param==2) {
    cat("$\\frac{\\theta_1}{\\theta_2}$", fill=TRUE)
} else {
  cat("$1-\\frac{\\theta_1}{\\theta_2}$", fill=TRUE)  
}
```

```{r title_descstats, eval=eval_final, results='asis'}
cat("# The Data", fill=TRUE)
```

```{r datahead, eval=evalfile2, results='asis'}
cat("## Data Head (first five observations)", fill=TRUE)
knitr::kable(head(df), col.names = c("Outcome", "Exposure"), linesep = '', longtable=T) %>%
  kable_styling(font_size = 8, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"))
```

\pagebreak

```{r desctable, eval=eval_final, results='asis'}
cat("## Frequency Table", fill=TRUE)
#cat("1st cell row is frequency, 2nd cell row is percent, 3rd cell row is row percent, 4th cell row is column percent.")
name_exposure = "Exposure"
name_nonexposure = "Non-Exposure"
name_outcome = "Outcome"
name_nonoutcome = "Non-Outcome"
rowsum_1 = n_exposure0 - n_exposure0_outcome1+n_exposure1 - n_exposure1_outcome1
rowsum_2 = n_exposure0_outcome1+n_exposure1_outcome1
freq_colnames = c(name_nonexposure, name_exposure,"Sum")
freq_rownames = c(name_nonoutcome, name_outcome,"Sum")
# compute frequencies and percentages
df_table <- as.data.frame.matrix(matrix(c(
  n_exposure0 - n_exposure0_outcome1, # Not exposed without outcome
  n_exposure1 - n_exposure1_outcome1, # Exposed without outcome
  rowsum_1, # sum no outcome
  n_exposure0_outcome1,               # Not exposed with outcome
  n_exposure1_outcome1,                # Exposed with outcome
  rowsum_2,
  n_exposure0,
  n_exposure1,
  n_exposure0+n_exposure1
), nrow = 3, byrow = TRUE))
colnames(df_table) <- freq_colnames
rownames(df_table) <- freq_rownames

totalsum <- n_exposure0+n_exposure1

df_table %>%
  kbl(caption = "Contingency Table: Absolute numbers") %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  row_spec(0, extra_css = "font-weight: normal; border-bottom: 2px solid;") %>%
  row_spec(nrow(df_table) - 1, extra_css = "border-bottom: 2px solid;") %>%   
  column_spec(1, extra_css = "border-right: 2px solid black;") %>%         
  column_spec(2, extra_css = "border-right: 1px solid lightgray;") %>%        
  column_spec(3, extra_css = "border-right: 2px solid black;") %>%               row_spec(1, extra_css = "border-top: 1px solid lightgray;")

df_table_percent<- as.data.frame.matrix(matrix(c(
  paste0(round((n_exposure0 -n_exposure0_outcome1)/totalsum*100,
               digits=2),"%"), 
  paste0(round((n_exposure1 - n_exposure1_outcome1)/totalsum*100,
               digits=2),"%"),
  paste0(round((n_exposure0 - n_exposure0_outcome1+n_exposure1 -
                  n_exposure1_outcome1)/totalsum*100,
               digits=2),"%"), 
  paste0(round((n_exposure0_outcome1)/totalsum*100,digits=2),"%"), 
  paste0(round((n_exposure1_outcome1)/totalsum*100,digits=2),"%"),            
  paste0(round((n_exposure0_outcome1+n_exposure1_outcome1)/totalsum*100,
               digits=2),"%"),
  paste0(round((n_exposure0)/totalsum*100,digits=2),"%"),
  paste0(round((n_exposure1)/totalsum*100,digits=2),"%"),
  paste0(100,"%")
), nrow = 3, byrow = TRUE))
colnames(df_table_percent) <- freq_colnames
rownames(df_table_percent) <- freq_rownames


df_table_percent %>%
  kbl(caption = "Contingency Table: Percentages of counts by total frequency") %>%
  kable_styling(full_width = FALSE, position = "center") %>%
  row_spec(0, extra_css = "font-weight: normal; border-bottom: 2px solid;") %>%
  row_spec(nrow(df_table) - 1, extra_css = "border-bottom: 2px solid;") %>%   
  column_spec(1, extra_css = "border-right: 2px solid black;") %>%         
  column_spec(2, extra_css = "border-right: 1px solid lightgray;") %>%        
  column_spec(3, extra_css = "border-right: 2px solid black;") %>%               row_spec(1, extra_css = "border-top: 1px solid lightgray;")

df_table_plot <- as.data.frame.matrix(matrix(c(
  n_exposure0 - n_exposure0_outcome1, # Not exposed without outcome
  n_exposure1 - n_exposure1_outcome1, # Exposed without outcome
  n_exposure0_outcome1,               # Not exposed with outcome
  n_exposure1_outcome1                # Exposed with outcome
), nrow = 2, byrow = TRUE))

colnames(df_table_plot) <- c(name_nonexposure, name_exposure)
rownames(df_table_plot) <- c(name_nonoutcome, name_outcome)

rowsum <- apply(df_table_plot, MARGIN  = 1, FUN = sum)
colsum <- apply(df_table_plot, MARGIN  = 2, FUN = sum)

cat("These two tables depict the frequencies and percentages of the total data. One can also calculate the column percentages per table:")
cat("<br>", fill=TRUE)

# cat("These two tables depict the frequencies and percentages of the total data. One can also calculate the row percentages and column percentages per table.")
# cat("<br>", fill=TRUE)
# ##row percent
# cat(paste0("Estimator for row percentages: \\begin{align} P(\\text{",name_nonexposure,"} \\ | \\ \\text{",name_nonoutcome,"} ) &= ",round((n_exposure0 - n_exposure0_outcome1)/rowsum_1 * 100,digits = 1),"\\% \\\\ P(\\text{",name_exposure,"} \\ | \\ \\text{",name_nonoutcome,"} ) &= ",round((n_exposure1 - n_exposure1_outcome1)/rowsum_1 * 100,digits = 1),"\\% \\\\ P(\\text{",name_nonexposure,"} \\ | \\ \\text{",name_outcome,"} ) &= ",round((n_exposure0_outcome1)/rowsum_2 * 100,digits = 1),"\\% \\\\ P(\\text{",name_exposure,"} \\ | \\ \\text{",name_outcome,"} ) &= ",round((n_exposure1_outcome1)/rowsum_2 * 100,digits = 1),"\\% \\end{align}"))


##column percent
cat(paste0("\\begin{align} P(\\text{",name_nonoutcome,"} \\ | \\ \\text{ ",name_nonexposure,"} ) &= ",round((n_exposure0 - n_exposure0_outcome1)/n_exposure0 * 100,digits = 2),"\\% \\\\ P(\\text{",name_outcome,"} \\ | \\ \\text{ ",name_nonexposure,"} ) &= ",round( n_exposure0_outcome1/n_exposure0 * 100,digits = 2),"\\% \\\\ P(\\text{",name_nonoutcome,"} \\ | \\ \\text{ ",name_exposure,"} ) &= ",round((n_exposure1-n_exposure1_outcome1)/n_exposure1 * 100,digits = 2),"\\% \\\\ P(\\text{",name_outcome,"} \\ | \\ \\text{ ",name_exposure,"} ) &= ",round((n_exposure1_outcome1)/n_exposure1 * 100,digits = 2),"\\% \\end{align}"))



# cat("<br>", fill=TRUE)
# cat(paste0("$P(\\text{",name_exposure,"} \\ | \\ \\text{ ",name_nonoutcome,"} ) = ",round((n_exposure1 - n_exposure1_outcome1)/rowsum_1 * 100,digits = 1),"\\%$"))
# cat("<br>", fill=TRUE)
# cat(paste0("$P(\\text{",name_nonexposure,"} \\ | \\ \\text{ ",name_outcome,"} ) = ",round((n_exposure0_outcome1)/rowsum_2 * 100,digits = 1),"\\%$"))
# cat("<br>", fill=TRUE)
# cat(paste0("$P(\\text{",name_exposure,"} \\ | \\ \\text{ ",name_nonoutcome,"} ) = ",round((n_exposure1_outcome1)/rowsum_2 * 100,digits = 1),"\\%$"))

# df_table_row <- as.data.frame.matrix(matrix(c(
#   (n_exposure0 - n_exposure0_outcome1)/rowsum_1, 
#   (n_exposure1 - n_exposure1_outcome1)/rowsum_1, 
#   (n_exposure0_outcome1)/rowsum_2,               
#   (n_exposure1_outcome1)/rowsum_2,                
# ), nrow = 2, byrow = TRUE))
# colnames(df_table) <- c("Placebo", "Vaccine")
# rownames(df_table) <- c("Non-Outcome", "Outcome")
# 
# 
# df_table_row %>%
#   kbl(caption = "Contingency Table: Absolute numbers") %>%
#   kable_styling(full_width = FALSE, position = "center") %>%
#   row_spec(0, extra_css = "font-weight: normal; border-bottom: 2px solid;") %>%
#   row_spec(nrow(df_table) - 1, extra_css = "border-bottom: 2px solid;") %>%   
#   column_spec(1, extra_css = "border-right: 2px solid black;") %>%         
#   column_spec(2, extra_css = "border-right: 1px solid lightgray;") %>%        
#   column_spec(3, extra_css = "border-right: 2px solid black;") %>%               row_spec(1, extra_css = "border-top: 1px solid lightgray;")

# 
# freq <- as.vector(t(df_table))
# perc_total <- paste( round(freq/totalsum,4)*100,"%")
# perc_row <- paste(round(freq/rep(rowsum,each=2),4)*100,"%")
# perc_col <-paste(round(freq/rep(colsum,2),4)*100,"%")
# 
# # put together frequencies and percentages in right order
# freq_perc_table <- as.data.frame(matrix(c(freq[1:2], perc_total[1:2], perc_row[1:2], perc_col[1:2], freq[3:4], perc_total[3:4], perc_row[3:4], perc_col[3:4]), ncol=2, byrow=T))
# 
# colnames(freq_perc_table) <-  colnames(df_table)
# 
# # add Total counts and perentages
# freq_perc_table["Total"]<- c(rowsum[1], paste(round(rowsum[1]/totalsum,4)*100,"%"), NA , NA , rowsum[2], paste(round(rowsum[2]/totalsum,4)*100,"%"), NA, NA)
# freq_perc_table <- rbind(freq_perc_table,c(colsum,totalsum))
# freq_perc_table <- rbind(freq_perc_table,c(paste(round(colsum/totalsum,4)*100,"%"),"100 %"))
# 
# # names for automated header and index names
# exp <- params$exposure
# exp_header <- c(exp = 2, " "= 1)
# names(exp_header) <- c(exp, " ")
# 
# #not_present_outcome <- unique(df[,colnames(df)==params$outcome])[unique(df[,colnames(df)==params$outcome])!=params$presence_outcome]
# 
# out_present <- paste(params$outcome,"=",rownames(df_table)[1])
# out_not_present <- paste(params$outcome,"=",rownames(df_table)[2])
# out_header <- c(out_present=4, out_not_present=4, "Total"=2)
# names(out_header) <- c(out_present, out_not_present, "Total")
# 
# # print table
# options(knitr.kable.NA = '')
# x1 <- knitr::kable(freq_perc_table, digits=2, escape = T, linesep = '', caption=cat(" ", fill=TRUE), longtable = T, align = "rrr")
# kable_styling(x1, position = "center", full_width = FALSE, latex_options = c("HOLD_position","repeat_header"),
#               bootstrap_options = c("condensed"))%>%
#   row_spec(4, hline_after = T)%>% 
#   row_spec(8,hline_after = T)%>% 
#   add_header_above(header = exp_header, escape = F)%>% 
#   pack_rows(index = out_header)

```


\pagebreak

```{r descplots, eval=eval_final, results='asis', fig.cap=' ', fig.subcap=c("Barplot of Outcome", "Barplot of Exposure", "Barplot of Outcome with present Exposure", "Barplot of Outcome without present Exposure" ), fig.ncol=2, out.width="50%", fig.align='left', out.height="30%"}
cat("## Barplots", fill=TRUE)

# Outcome
barplot(rowsum / totalsum, ylim = c(0, 1), names.arg = rownames(df_table_plot), xlab = "Outcome", ylab = "Proportion", col = c("#2fa42d", "#396e9f"), main=paste("Distribution in the Population"), cex.main = 1.5)

# Exposure
barplot(colsum / totalsum, ylim = c(0, 1), names.arg = colnames(df_table_plot), xlab = "Exposure", ylab = "Proportion", col = c("#2fa42d", "#396e9f"), main=paste("Distribution in the Population"), cex.main = 1.5)

#  Outcome with present Exposure
barplot(c(n_exposure1-n_exposure1_outcome1,n_exposure1_outcome1)/n_exposure1,ylim=c(0,1), xlab="Outcome", ylab ="Proportion", col=c("#2fa42d","#396e9f"), main=paste("Distribution in the Exposed Population"), cex.main = 1.5)

#  Outcome without present Exposure
barplot(c(n_exposure0 - n_exposure0_outcome1, n_exposure0_outcome1) / n_exposure0, ylim = c(0, 1), xlab = "Outcome", ylab = "Proportion", col = c("#2fa42d", "#396e9f"), main=paste("Distribution in the NOT Exposed Population"), cex.main = 1.5)

```

\pagebreak

```{r the_model, eval=eval, results='asis'}
cat("# The Model", fill=TRUE)
cat("\n## Notation", fill=TRUE)
cat("The statistical model of this analysis derives from the data ", fill=TRUE)
cat("$$X_{11},...,X_{1n_1} \\hspace{1cm} i.i.d. \\sim Be(\\theta_1) \\, ,$$", fill=TRUE)
cat("$$X_{21},...,X_{2n_2} \\hspace{1cm} i.i.d.  \\sim Be(\\theta_2)$$", fill=TRUE)
cat(paste0("with sample sizes $n_1=$ ",n_exposure1," and $n_2=$ ",n_exposure0," and Bernoulli distributed random variables in the two groups with distribution parameter $\\theta_i \\, , i\\in\\{1,2\\}$.\\
The Exposure variable indicates in which of the two groups (",colnames(df_table)[1]," and ",colnames(df_table)[2], ") an individual is. The Outcome variable indicates whether the event occurred for an individual or not and corresponds to either a value of 1 or 0. \\"), fill=TRUE)
cat("Summing up the values of 0 and 1 in the respective groups results in the following random variables:", fill=TRUE)
cat("$$Y_1= \\sum_{i=1}^{n_1} X_{1i} \\hspace{1cm} i.i.d.  \\sim Bi(n_1,\\theta_1) \\, ,$$", fill=TRUE)
cat("$$Y_2= \\sum_{i=1}^{n_2} X_{2i} \\hspace{1cm} i.i.d. \\sim Bi(n_2,\\theta_2) \\, .$$", fill=TRUE)
cat("These random variables are binomially distributed with the distribution parameters $n_i$ and $\\theta_i \\, , i\\in\\{1,2\\}$. \\", fill=TRUE)
cat("The selected function ", fill=TRUE)
if (params$user_selection_function_param==1) {
  cat("$\\theta_1 - \\theta_2$, describes the difference between two success probabilities.", fill=TRUE)
} else {
  if (params$user_selection_function_param==2) {
  cat("$\\theta_1 / \\theta_2$, describes the Relative Risk, e.g. ratio of two success probabilities.", fill=TRUE)
} else {
  cat("$1-\\theta_1 / \\theta_2$, describes 1-Relative Risk, where Relative Risk is e.g. the ratio of two probabilities of success.", fill=TRUE)  
}
}

```

```{r likelihood, eval=eval_final, results='asis'}
cat("## The Likelihood", fill=TRUE)

cat("The likelihood function is a function of $(\\theta_1, \\theta_2 )$ that describes the plausibility of $(Y_1,Y_2)=(y_1,y_2)$ with different $(\\theta_1, \\theta_2 )$. The likelihood function should not be confused with a probability function.", fill = TRUE)
cat("<br>", fill=TRUE)
cat("Let $$(Y_1,Y_2) \\sim f(Y_1,Y_2 \\ | \\ \\theta_1, \\theta_2)\\, ,$$ where $f$ is a probability mass function with")
cat("<br>", fill=TRUE)
#Likelihood formula of D given theta_1 and theta_2
cat("\\begin{align} f(y_1,y_2) = P(Y_1=y_1,Y_2=y_2 \\ | \\ \\theta_1, \\theta_2) &= P(Y_1=y_1 \\ | \\ \\theta_1, \\theta_2) \\cdot P(Y_2=y_2 \\ | \\ \\theta_1, \\theta_2) \\\\[1em] &= \\underbrace{P(Y_1=y_1 \\ | \\ \\theta_1)}_{\\sim Bi(n_1,\\theta_1)} \\cdot \\underbrace{P(Y_2=y_2 \\ | \\ \\theta_2)}_{\\sim Bi(n_2,\\theta_2)} \\\\[1em] &= \\begin{pmatrix} n_1 \\\\ y_1 \\end{pmatrix} \\theta_1^{y_1} (1-\\theta_1)^{n_1 - y_1} \\cdot \\begin{pmatrix} n_2 \\\\ y_2 \\end{pmatrix} \\theta_2^{y_2}(1-\\theta_2)^{n_2 - y_2}\\, . \\end{align}")
cat("<br>", fill=TRUE)
cat("The likelihood function is defined as follows $L: [0,1] \\times [0,1] \\to [0, \\infty)$ with", fill = TRUE)
cat("<br>", fill=TRUE)
cat("$$L(\\theta_1, \\theta_2 \\ | \\ y_1,y_2) = \\begin{pmatrix} n_1 \\\\ y_1 \\end{pmatrix} \\theta_1^{y_1} (1-\\theta_1)^{n_1 - y_1} \\cdot  \\begin{pmatrix} n_2 \\\\ y_2 \\end{pmatrix} \\theta_2^{y_2}(1-\\theta_2)^{n_2 - y_2} \\, .$$", fill=TRUE)
cat("<br>", fill=TRUE)
#Likelihood formular of D given theta_1 and theta_2 with user entered data
cat(paste0("Consider our data $n_1=", n_exposure1, ", n_2=", n_exposure0, ", y_1=", n_exposure1_outcome1, ", y_2=", n_exposure0_outcome1,"$:"),fill=TRUE)
cat("<br>", fill=TRUE)
cat(paste0("$$P(Y_1=", n_exposure1_outcome1, ",Y_2=", n_exposure0_outcome1, " \\ | \\ \\theta_1, \\theta_2) = \\begin{pmatrix} ", n_exposure1, " \\\\ ", n_exposure1_outcome1," \\end{pmatrix} \\theta_1^{", n_exposure1_outcome1, "}(1-\\theta_1)^{", n_exposure1, " - ", n_exposure1_outcome1, "} \\cdot  \\begin{pmatrix} ", n_exposure0, " \\\\ ", n_exposure0_outcome1," \\end{pmatrix} \\theta_2^{", n_exposure0_outcome1, "}(1-\\theta_2)^{", n_exposure0, " - ", n_exposure0_outcome1, "} \\, .$$"), fill=TRUE)
cat("<br>", fill=TRUE)
cat(paste0("Then $$L(\\theta_1, \\theta_2 \\ | \\ y_1=", n_exposure1_outcome1, ",y_2=", n_exposure0_outcome1, ")=\\begin{pmatrix} ", n_exposure1, " \\\\ ", n_exposure1_outcome1," \\end{pmatrix} \\theta_1^{", n_exposure1_outcome1, "}(1-\\theta_1)^{", n_exposure1, " - ", n_exposure1_outcome1, "} \\cdot  \\begin{pmatrix} ", n_exposure0, " \\\\ ", n_exposure0_outcome1," \\end{pmatrix} \\theta_2^{", n_exposure0_outcome1, "}(1-\\theta_2)^{", n_exposure0, " - ", n_exposure0_outcome1, "} \\, .$$"),fill=TRUE)
cat("<br>", fill=TRUE)
cat("Examples for selected $(\\theta_1, \\theta_2)$, given our data:", fill=TRUE)

# Define likelihood function (adjust if needed)
likelihood <- function(theta, successes, trials) {
  if (any(trials <= 0)) stop("Trials must be greater than 0")
  if (any(successes < 0)) stop("Successes must be non-negative")
  if (any(theta <= 0 | theta >= 1)) stop("Theta must be between 0 and 1")
  dbinom(successes, size = trials, prob = theta)
}

L1 = likelihood(n_exposure1_outcome1/n_exposure1,n_exposure1_outcome1,n_exposure1)*likelihood(n_exposure0_outcome1/n_exposure0,n_exposure0_outcome1,n_exposure0)
L2 = likelihood(0.5,n_exposure1_outcome1,n_exposure1)*likelihood(0.5,n_exposure0_outcome1,n_exposure0)

cat("<br>", fill=TRUE)
cat(paste0("\\begin{align} L \\biggl( \\theta_1= \\frac{", n_exposure1_outcome1, "}{", n_exposure1, "}, \\theta_2= \\frac{", n_exposure0_outcome1, "}{", n_exposure0, "} \\ \\biggl | \\ y_1=", n_exposure1_outcome1, ", y_2=", n_exposure0_outcome1, " \\biggl) &=", round(L1,4),"\\, , \\\\[1em] L(\\theta_1= 0.5, \\theta_2= 0.5 \\ | \\  y_1=", n_exposure1_outcome1, ", y_2=", n_exposure0_outcome1, ") &=", round(L2,4),"\\, .\\end{align}"), fill=TRUE)
cat("<br>", fill=TRUE)
cat("Remark: Because of the independence of $Y_1$ and $Y_2$ you can get the following marginal distributions: ",fill=TRUE) 
#Marginal distribution of D_1 given theta_1 and of D_2 given theta_2
cat("\\begin{align} P(Y_1=y_1 \\ | \\ \\theta_1 ) &= \\begin{pmatrix} n_1 \\\\ y_1 \\end{pmatrix} \\theta_1^{y_1}(1-\\theta_1)^{n_1 - y_1} \\, , \\\\[1em] P(Y_2=y_2 \\ | \\ \\theta_2) &= \\begin{pmatrix} n_2 \\\\ y_2 \\end{pmatrix} \\theta_2^{y_2}(1-\\theta_2)^{n_2 - y_2} \\, . \\end{align}", fill = TRUE)

## Region to plot 
Theta1 = seq(0.01, 0.99, by=0.01)  
Theta2 = seq(0.01, 0.99, by=0.01)

#Calculation of both marginal distributions
l1 = likelihood(Theta1, n_exposure1_outcome1, n_exposure1)
l2 = likelihood(Theta2, n_exposure0_outcome1, n_exposure0)

#Matrix multiplication to calculate likelihood of D given theta_1 and theta_2
Likelihood = l1 %*% t(l2)

#Generation of the surface plot of D given theta_1 and theta_2
#with white x and y dimensional contour lines
fig <- plot_ly(z = ~Likelihood, x = ~Theta1, y = ~Theta2, contours = list(x = list(show = TRUE, start= 0, end= 1, size = 0.05 ,color = 'white'), y = list(show = TRUE, start= 0, end= 1, size = 0.05 ,color = 'white')))

#Adding a description when hovering over the surface of plot
#with description of the values of theta_1, theta_2 and the likelihood
fig <- fig %>% add_surface(hovertemplate = paste0('\u03b8\u2081: %{x}<br>', '\u03b8\u2082: %{y}<br>', 'p(D | \u03b8\u2081, \u03b8\u2082): %{z}<extra></extra>'))

#Adding axis labeling of surface plot with theta_1, theta_2 and likelihood
fig <- fig %>% layout(scene = list(camera = list(eye = list(x = -1.5, y = -1.5, z = 1.5)),
                                   xaxis=list(title = "\u03b8\u2081"), 
                                   yaxis=list(title = "\u03b8\u2082"), 
                                   zaxis=list(title = "L(\u03b8\u2081, \u03b8\u2082 | y\u2081, y\u2082)"), 
                                   title = "theta"))
#Display plot in report  
fig
```

```{r priortext, eval=eval_final, results='asis'}
cat("## The Prior Distribution", fill=TRUE)
cat("Preliminary information is included in the analysis with the help of the prior distribution.
For binomially distributed measurement data, a beta distribution is suitable as a priori distribution: \n",fill=TRUE)

cat("\\begin{align}(\\theta_1, \\theta_2) \\sim p(\\theta_1,\\theta_2) = p(\\theta_1) \\cdot p(\\theta_2) &= beta(a_1,b_1) \\cdot beta(a_2,b_2) \\\\[1em] &= \\frac{1}{B(a_1,b_1)} \\theta_1^{a_1-1} \\left(1-\\theta_1\\right)^{b_1-1} \\cdot \\frac{1}{B(a_2,b_2)} \\theta_2^{a_2-1} \\left(1-\\theta_2\\right)^{b_2-1}\\end{align}",fill=TRUE)
cat("with $B$ as the beta function (also called \'Euler integral of the first kind\').",fill=TRUE)
cat("<br>", fill=TRUE)
cat("We assume that the beliefs about the two parameters are independent, i.e. $\\theta_1$ and $\\theta_2$ are independent, with marginal belief distributions $p(\\theta_1)$, $p(\\theta_2)$.",fill = TRUE) 
cat("<br>", fill=TRUE)
cat("<br>", fill=TRUE)

# no default parameters
if(a1!=0.5 | b1!=0.5 | a2!=0.5 | b2!=0.5){
  cat("Your choice of the parameters for the prior distributions is:\n ")
  cat(paste("$$(\\theta_1, \\theta_2) \\sim beta(",a1,",",b1,") \\cdot
            beta(",a2,",",b2,").$$"),fill=TRUE)
  
  # mode exists
  if(a1 > 1 & b1 > 1 & a2 > 1 & b2 > 1){
    
    # same values
    if(a1 == a2 & a1 == b1 & a1 == b2){
    cat("In this case, all parameters were chosen to be the same. This means that it was assumed that little or no information about the parameters to be estimated was known in advance. The maximum of the prior distribution is therefore at $(0.5, 0.5)$.",fill=TRUE)
    # different values
    } else{
    t1_m = round((a1-1)/(a1+b1-2), digits=3)
    t2_m = round((a2-1)/(a2+b2-2), digits=3)
    cat(paste0("In this case, not all parameters were chosen to be the same. This means that it was assumed that there was information about the parameters in advance. The prior is peaked in $(",t1_m,", ",t2_m,")$."),fill=TRUE)
    }
  
  # mode does not exist  
  } else{
    
    # same values
    if(a1 == a2 & a1 == b1 & a1 == b2){
    cat("In this case, all parameters were chosen to be the same. This means that it was assumed that little or no information about the parameters to be estimated was known in advance.",fill=TRUE)
    # different values
    } else{
    cat("In this case, not all parameters were chosen to be the same. This means that it was assumed that there was information about the parameters in advance.",fill=TRUE)
    }
    
  }

# default parameters    
} else{
  cat("The default parameters are chosen: \n",fill=TRUE)
  cat("$$(\\theta_1, \\theta_2) \\sim  beta(0.5,0.5) \\cdot beta(0.5,0.5) \\, .$$",fill=TRUE)
  cat("These default parameters have their origin in the so called Jeffrey's prior which is a non-informative prior distribution. Non-informative prior distributions are used when little or no information is available about the parameters to be determined and therefore no statement can be made about the distribution of the parameters. In our assumed situation we have two parameters $\\theta_1$ and $\\theta_2$. In the following, Jeffrey's prior is described for one general $\\theta$, but we can use these results from Jeffrey's prior and insert them in both of the beta distributions multiplied in our prior. The priors $p(\\theta)=beta(0.5,0.5)$ result from Jeffrey's rule $$p(\\theta) \\propto \\sqrt{I(\\theta)}$$ where $I(\\theta)$ is the Fisher information function $$I(\\theta)=-E\\left[ \\frac{\\partial^2}{\\partial \\theta^2} L(\\theta \\ | \\ \\bullet) \\right]$$ and where $L(\\theta \\ | \\ \\bullet)$ is the likelihood function of the data $\\bullet$.",fill=TRUE)
  cat("<br>", fill=TRUE)
  cat("In our case, the likelihood is a binomial distribution. Hence, the Fisher information function is $$I(\\theta)=\\frac{1}{\\theta (1-\\theta)} \\, .$$ This results in $$p(\\theta) \\propto \\theta^{-0.5}(1-\\theta)^{-0.5}$$ because of Jeffrey's rule. The resulting prior distribution is now $beta(0.5,0.5)$.",fill=TRUE)
cat("The default shape parameters of the beta distributions indicate that the prior distribution is peaked at $(0.5,0.5)$ which represents a mild prior belief.")
}
cat("<br>", fill=TRUE)
cat("<br>", fill=TRUE)
cat("Note that when choosing the prior distribution, the amount of information already known about the probabilities $\\theta_1$ and $\\theta_2$ should be taken into account. If not so much or nothing at all is known, $a_i = b_i$ should be selected for the distribution of $\\theta_i$, $i=1,2$, so that the  mean and the mode are equal to $0.5$. In general, the mean $\\mu_i$ and the mode $\\omega_i$ can be calculated as follows: $$ \\mu_i = \\frac{a_i}{a_i+b_i} \\text{ and } \\omega_i = \\frac{a_i -1}{a_i+b_i-2} \\, , \\  a_i,b_i > 1 \\, . $$",fill=TRUE)
cat("So if $a_i>b_i$, $\\mu_i$ and $\\omega_i$ are greater than $0.5$ and if $a_i<b_i$, $\\mu_i$ and $\\omega_i$ are less than $0.5$. So the prior distribution as a product of two $beta(a_i,b_i)$ distributions is peaked in $(\\omega_1,\\omega_2)$ when $a_i,b_i > 1$ for all $i=1,2$ because all values of the beta density are greater than or equal to $0$. The greater the sum $a_i+b_i$, the more confident one is in the assumption of the tendencies for $\\theta_i$.")






```


```{r priorplot, eval=eval_final, results='asis'}
# Plot the prior (follow first row from page 167 DDBA)
cat("The next plot shows the probability density function (pdf) of the prior distribution.",fill=TRUE)


# Bounding for density values -> better colourscaling
pTheta1 = dbeta(Theta1,params$a1,params$b1)
pTheta2 = dbeta(Theta2,params$a2,params$b2)
pTheta1Theta2 <- pTheta1 %*% t(pTheta2)

scene = list(camera = list(eye = list(x = -1.5, y = -1.5, z = 1.5)),
             xaxis = list(title = "\u03b8\u2081"),
             yaxis = list(title = "\u03b8\u2082"),
             zaxis = list(title = "p(\u03b8\u2081, \u03b8\u2082)" ))
plt3d <- plot_ly(x = Theta1, y = Theta2, z = pTheta1Theta2, type = "surface",
                 contours = list(
                   x = list(show = TRUE, start= 0, end= 1, size = 0.05 ,color = 'white'),
                   y = list(show = TRUE, start= 0, end= 1, size = 0.05 ,color = 'white')))%>%
          layout(scene=scene)
plt3d
```


```{r posterior1, eval=TRUE, results='asis'}
cat("## The Posterior Distribution", fill=TRUE)
# Insert latex or code equation for the posterior distribution 
cat("The posterior distribution is an update of the prior distribution using the likelihood. \\cite{kruschke} This probability distribution shows how strongly we should believe in the various parameter values after we have seen the data $(y_1,y_2)$ out of $(n_1,n_2)$. It is calculated with the help of Bayes theorem. In what follows we derive the posterior in general terms for arbitrary sample sizes and outcome summaries")  
cat("\\begin{align}
    p(\\theta_1,\\theta_2 \\ | \\ y_1,y_2)&=\\frac{p(y_1,y_2 \\ | \\ \\theta_1,\\theta_2)p(\\theta_1,\\theta_2)}{p(y_1,y_2)} \\, ,
    \\end{align}")
cat("where \\begin{align} 
        p(y_1,y_2 \\ | \\ \\theta_1,\\theta_2) &= L(\\theta_1,\\theta_2 \\ | \\ y_1,y_2)
        \\end{align}
        is the likelihood function and
        \\begin{align}
        p(y_1,y_2) &= \\int \\int
        p(y_1,y_2 \\ | \\ \\theta_1,\\theta_2)p(\\theta_1,\\theta_2) \\ d \\theta_1 d
        \\theta_2 
    \\end{align} is a normalizing constant.")
cat("<br>",fill=TRUE) 
cat("Including the likelihood and the assumed prior distributions of the $\\theta_i$,  $i=1,2$, we get the numerator of the Bayes theorem:")
cat("\\begin{align}
    z = \\underbrace{\\binom{n_1}{y_1}\\theta_1 ^{y_1}(1-\\theta_1)^{n_1-y_1} \\cdot \\binom{n_2}{y_2}\\theta_2 ^{y_2}(1-\\theta_2)^{n_2-y_2}}_{\\text{likelihood function}} \\cdot \\underbrace{\\frac{\\theta_1^{a_1-1}(1-\\theta_1)^{b_1-1}}{B(a_1,b_1)}}_{\\text{prior } \\theta_1} \\cdot \\underbrace{\\frac{\\theta_2^{a_2-1}(1-\\theta_2)^{b_2-1}}{B(a_2,b_2)}}_{\\text{prior } \\theta_2} \\, . \\end{align}")
cat("Now we can insert this in the actual Bayes theorem. With some power calculations we get:")
cat("\\begin{align}
     p(\\theta_1,\\theta_2 \\ | \\ y_1,y_2) &= 
     \\frac{\\frac{\\binom{n_1}{y_1}\\binom{n_2}{y_2}}{B(a_1,b_1)B(a_2,b_2)}
     \\cdot \\theta_1^{y_1+a_1-1}(1-\\theta_1)^{n_1-y_1+b_1-1}\\cdot\\theta_2^
     {y_2+a_2-1}(1-\\theta_2)^{n_2-y_2+b_2-1}}{p(y_1,y_2)} \\\\[1em]
     &= \\frac{\\theta_1^{y_1+a_1-1}(1-\\theta_1)^{n_1-y_1+b_1-1}\\cdot\\theta_
     2^{y_2+a_2-1}(1-\\theta_2)^{n_2-y_2+b_2-1}}{B(a_1+y_1,b_1+n_1-y_1)\\cdot
     B(a_2+y_2,n_2-y_2+b_2) } \\, .
     \\end{align}")

cat("The last step in this computation follows from the normalizing constant and the condition that a density has to integrate to one. $B(\\cdot,\\cdot)$ are the normalizing constants of the Beta-distribution. ")
cat("Hence, our posterior function is distributed as follows:
    \\begin{align}
    \\left( \\theta_1,\\theta_2 \\ | \\ y_1,y_2 \\right) \\sim beta(a_1+y_1,b_1+n_1-y_1) \\cdot 
    beta(a_2+y_2, n_2+b_2-y_2) \\, . 
    \\end{align}")
cat("As can be seen here, the $\\theta_i$, $i=1,2$, are independent under the posterior. For our model assumptions, the posterior distribution has the following form:", fill=TRUE)
cat(paste0("\\begin{align} p(\\theta_1,\\theta_2 \\ | \\ ", n_exposure1_outcome1,",",n_exposure0_outcome1,")
&= beta(",a1,"+",n_exposure1_outcome1,",",b1,"+",n_exposure1,"-",n_exposure1_outcome1,") \\cdot beta(",a2,"+",n_exposure0_outcome1,",",b2,"+",n_exposure0,"-",n_exposure0_outcome1,") \\\\
&= beta(",a1+n_exposure1_outcome1,",",b1+n_exposure1-n_exposure1_outcome1,") \\cdot beta(",a2+n_exposure0_outcome1,",",b2+n_exposure0-n_exposure0_outcome1,") \\, .  \\end{align}"))
```


```{r posterior2, eval=TRUE, results='asis'}
# Posterior for plotting (follow last row from page 167 DDBA)
pTheta1Theta2GivenData <- matrix(data=NA, nrow=length(Theta1), ncol=length(Theta2))
for (i in 1:length(Theta1)){
  for (j in 1:length(Theta2)){
    pTheta1Theta2GivenData[i,j]<- dbeta(Theta1[i], a1+n_exposure1_outcome1, b1+n_exposure1-n_exposure1_outcome1)*dbeta(Theta2[j], a2+n_exposure0_outcome1, b2+n_exposure0-n_exposure0_outcome1)   
  }
} 
cat("The following figure shows the probability density function (pdf):  ", fill=TRUE)
## Generate plot, export as a png and include or find another solution 
 plot_ly(x = Theta1, y = Theta2, z = pTheta1Theta2GivenData, type = "surface",
         contours = list(
          x = list(show = TRUE, start= 0, end= 1, size = 0.05 ,color = 'white'),
          y = list(show = TRUE, start= 0, end= 1, size = 0.05 ,color = 'white')))%>%
         layout(scene = list(camera = list(eye = list(x = -1.5, y = -1.5, z = 1.5)),
             xaxis = list(title = "\u03b8\u2081"),
             yaxis = list(title = "\u03b8\u2082"),
             zaxis = list(title = "p(\u03b8\u2081, \u03b8\u2082 \u2223 y\u2081, y\u2082)" )))
 
cat("In the figure, at each point in the parameter space ($\\theta_1$,$\\theta_2$), the posterior is the product of the prior and likelihood values at that point divided by the normalizer $p(y_1,y_2)$. Thus, it is proportional to the prior and the likelihood (posterior $\\propto$ prior x likelihood).") 

```

```{r simulate, eval=eval}
## Simulate from posterior
posterior_Theta1 <- rbeta(10000,n_exposure1_outcome1+a1,(n_exposure1-n_exposure1_outcome1)+b1)
posterior_Theta2 <- rbeta(10000,n_exposure0_outcome1+a2,(n_exposure0-n_exposure0_outcome1)+b2)
```

```{r functionparameter, eval=eval_final}
## Function of parameters of interest
if (params$user_selection_function_param == 3) {
  estimate <- 1-posterior_Theta1/posterior_Theta2
} else if (params$user_selection_function_param == 2){
  estimate <- posterior_Theta1/posterior_Theta2  
} else {
  estimate <- posterior_Theta1-posterior_Theta2  
}
```

```{r function_posterior, eval=eval_final, results="asis"}
cat("# Inference with respect to Posterior", fill=TRUE)
cat("\n## Summary", fill=TRUE)
```


```{r function_posterior2, eval=eval_final}
# Summarize posterior in a table. For continuous parameters, derived functions of parameters and predicted values, report the central tendency and limits of the credible interval. Explicitly state whether you are using density-based values (mode and HDI) or quantile-based values (median and ETI), and state the mass of the credible interval (for example, 95%)
if (is.null(rope_user)){
  a <- describe_posterior(estimate, ci = 0.95, centrality="all", dispersion=TRUE, test=NULL, ci_method = "ETI") 
  b <- describe_posterior(estimate, ci = 0.95, centrality="all", dispersion=TRUE, test=NULL, ci_method = "HDI")

} else {
  a <- describe_posterior(estimate, ci = 0.95, centrality="all", dispersion=TRUE, test="rope", rope_range=rope_user, ci_method = "ETI") 
  b <- describe_posterior(estimate, ci = 0.95, centrality="all", dispersion=TRUE, test="rope", rope_range=rope_user, ci_method = "HDI")

  # ROPE limits and decisions. 
}

# Umbennennung der Spaltennamen
colnames(a)[colnames(a) == "CI"] <- "CI_ETI"
colnames(a)[colnames(a) == "CI_low"] <- "CI_ETI_low"
colnames(a)[colnames(a) == "CI_high"] <- "CI_ETI_high"

# Kombinieren der Dataframes
combined_results <- cbind(a, CI_HDI = b$CI, CI_HDI_low = b$CI_low, CI_HDI_high = b$CI_high)

# Bearbeiten des Dataframes 
a2 <- data.frame(t(combined_results), interpretation = rep(1,12))
a2 <- data.frame(parameter =  rownames(a2)[-1], posterior = round(as.numeric(t(combined_results)[-1]),3))

# Function für die Interpretation
interpretation_func <- function(dataset) {
  interpretation <- c()  
  for (i in 1:nrow(dataset)) {
    if (dataset$parameter[i] == "Median") {
      interpretation[i] <- paste("The median is the middle value of the distribution. It divides the data into two                                   equal halves, where 50% of the values lie below and 50% lie above this point. In                                    this case, the median is", dataset$posterior[i], ", meaning that the central value                                  of the distribution is", dataset$posterior[i], ".")
    } else if (dataset$parameter[i] == "MAD") {
      interpretation[i] <- paste("The MAD (Median Absolute Deviation) is a measure of variability, based on the                                      median. It represents the median of the absolute deviations from the                                               median. Here, the MAD is", 
                                 dataset$posterior[i], ", indicating that the typical deviation of data points from                                  the median is", dataset$posterior[i], ".")
    } else if (dataset$parameter[i] == "Mean") {
      interpretation[i] <- paste("The mean is the arithmetic average of the distribution, calculated by summing all                                  values and dividing by their count. In this case, the mean is", 
                                 dataset$posterior[i], ", representing the average value of the distribution.")
    } else if (dataset$parameter[i] == "SD") {
      interpretation[i] <- paste("The SD (Standard Deviation) is a measure of the spread of the data around the                                      mean. It shows the average deviation of values from the mean. Here, the SD is", 
                                 dataset$posterior[i], ", meaning that on average, data points deviate by",                                          dataset$posterior[i], "from the mean.")
    } else if (dataset$parameter[i] == "MAP") {
      interpretation[i] <- paste("MAP (Maximum A Posteriori) is the value with the highest density in the posterior                                  distribution. It represents the mode (peak) of the estimated probability density                                    function. MAP of", dataset$posterior[i], "indicates that this is the most                                           likely value in the distribution.")
    } else if (dataset$parameter[i] == "CI_ETI") {
      interpretation[i] <- paste("The CI (Credible Interval) represents the range where the true parameter value is                                  likely to lie. This CI_ETI is based on quantiles (Equal-Tail Interval, ETI), which                                      covers the central 95% of the posterior distribution, with equal probability in the                                  tails.")
    } else if (dataset$parameter[i] == "CI_ETI_low") {
      interpretation[i] <- paste("The lower bound of the 95% ETI indicates that the true value is not likely to be                                   smaller than", dataset$posterior[i], "with 95% credibility.")
    } else if (dataset$parameter[i] == "CI_ETI_high") {
      interpretation[i] <- paste("The upper bound of the 95% ETI indicates that the true value is not likely to                                      exceed", dataset$posterior[i], "with 95% credibility.")
    } else if (dataset$parameter[i] == "CI_HDI") {
      interpretation[i] <- paste("The CI (Credible Interval) represents the range where the true parameter value is                                  most likely to lie. This CI_HDI is based on density (Highest Density Interval, HDI),                                     which covers the 95% of the posterior distribution with the highest density.")
    } else if (dataset$parameter[i] == "CI_HDI_low") {
      interpretation[i] <- paste("The lower bound of the 95% HDI indicates that the true value is unlikely to be                                     smaller than", dataset$posterior[i], "with 95% credibility, based on the highest                                    density.")
    } else if (dataset$parameter[i] == "CI_HDI_high") {
      interpretation[i] <- paste("The upper bound of the 95% HDI indicates that the true value is unlikely to                                        exceed", dataset$posterior[i], "with 95% credibility, based on the highest                                          density.")
    }
    
  }
  return(interpretation)
}

```

```{r}
# Summary Tabelle
a3 <-  data.frame(a2, interpretation = interpretation_func(a2))
```

```{r}
# Zeige die Tabelle mit knitr::kable()
kable(a3, align = "l",caption = "Summary of Posterior Distribution") %>%
  kable_styling(full_width = TRUE)
```


```{r plot_hdi, eval=eval_final, results="asis"}
cat("## HDI Plot", fill=TRUE)
# Display graphical posterior information using bayestestR package

xlabel <- if (params$user_selection_function_param == 1){
  expression(theta[1] - theta[2])
  } else if (params$user_selection_function_param == 2){
  expression(frac(theta[1],theta[2]))
  } else if (params$user_selection_function_param == 3){
  expression(1 - frac(theta[1],theta[2]))

}
hdi_result <- hdi(estimate, ci = c(.89, .95, .99))

hdi_plot_temp = plot(hdi_result)

# Display the HDI plot
hdi_plot <- plot(x=hdi_result, y=hdi_plot_temp[["data"]][["height"]]) +
  labs(
    x = xlabel,                 # Label for the x-axis
    y = "Density of the Posterior Distribution",                   # Label for the y-axis
    title = "Highest Density Interval (HDI)" # Title for the plot
  ) +
  theme_minimal(base_size = 14) +    # Apply a clean theme with readable font size
  theme(
    plot.title = element_text(hjust = 0.5),  # Center the plot title
    legend.position = "right",               # Keep legend on the right
    legend.text = element_text(size = 10),   # Reduce legend text size
    legend.title = element_text(size = 11),  # Reduce legend title size
    panel.background = element_rect(fill = "gray95", color = NA),  # Light gray background
    panel.grid.major = element_line(color = "white"),              # Major grid lines in white
    panel.grid.minor = element_line(color = "white")               # Minor grid lines in white
  ) +
  scale_y_continuous(breaks = seq(0, max(hdi_plot_temp[["data"]][["height"]]), length.out = 5))  # 5 values for the y-axis


print(hdi_plot)

# Textuelle Interpretation - Dynamic Expression
cat("\n\n**Interpretation:**\n\n")
cat("This plot shows the Highest Density Intervals (HDI) for a posterior distribution, illustrating the most credible values for the parameter ")

# Direkte LaTeX-Notation für xlabel
if (params$user_selection_function_param == 1) {
  cat("\\(\\theta_1 - \\theta_2\\)")
} else if (params$user_selection_function_param == 2) {
  cat("\\(\\frac{\\theta_1}{\\theta_2}\\)")
} else if (params$user_selection_function_param == 3) {
  cat("\\(1 - \\frac{\\theta_1}{\\theta_2}\\)")
}

cat("\n\nThe curve represents the probability density of the parameter values, with the shaded regions highlighting different HDI levels. ",
    "The red area corresponds to the 89% HDI, which captures the majority of the distribution’s density and represents the most credible range. ",
    "The pink region extends this to 95%, including slightly more of the distribution, while the green and blue regions narrow further, covering 99% and 100% of the density, respectively. ",
    "Overall, the HDIs provide a visual summary of where the most credible parameter estimates lie, while reflecting the uncertainty inherent in the data. ",
    "The 95% HDI includes all those values of x for which the density is at least as big as some value W, such that the integral over all those x values is 95%. Formally, the values of x in the 95% HDI are those such that\n")

cat("\\begin{align*}\n",
    "    \\text{HDI}_{95\\%} &= \\left\\{ x \\mid p(x) > W \\right\\} ",
    "    \\text{with} \\quad \\int_{x : p(x) > W} p(x) \\, dx &= 0.95\n",
    "\\end{align*}")
cat("(Kruschke, John K., Doing Bayesian Data Analysis, Academic Press, 2015)")
```

```{r plot_eti, eval=eval_final, results="asis"}
cat("## ETI Plot", fill=TRUE)

# Display the ETI plot
eti_result = eti(estimate, ci = c(.89, .95, .99))

eti_plot_temp = plot(eti_result)

# Create the plot
eti_plot <- plot(x=eti_result, y=eti_plot_temp[["data"]][["height"]]) +
  labs(
    x = xlabel,       # Dynamic x-label
    y = "Density of the Posterior Distribution",     # Label for the y-axis
    title = "Credible Interval (CI)" # Title for the plot
  ) +
  theme_minimal(base_size = 14) +        # Minimalist theme with readable font size
  theme(
    plot.title = element_text(hjust = 0.5),  # Center the title
    legend.position = "right",               # Position the legend on the right
    legend.text = element_text(size = 10),   # Reduce font size for legend text
    legend.title = element_text(size = 11),  # Reduce font size for legend title
    panel.background = element_rect(fill = "gray95", color = NA),  # Light gray background
    panel.grid.major = element_line(color = "white"),              # White major grid lines
    panel.grid.minor = element_line(color = "white")               # White minor grid lines
  ) +
  scale_y_continuous(breaks = seq(0, max(eti_plot_temp[["data"]][["height"]]), length.out = 5))  # 5 values for the y-axis

print(eti_plot)


# Add text interpretation
cat("\n\n**Interpretation:**\n\n")
cat("This plot displays the posterior distribution of a specified parameter ")
if (params$user_selection_function_param == 1) {
  cat("\\(\\theta_1 - \\theta_2\\)")
} else if (params$user_selection_function_param == 2) {
  cat("\\(\\frac{\\theta_1}{\\theta_2}\\)")
} else if (params$user_selection_function_param == 3) {
  cat("\\(1 - \\frac{\\theta_1}{\\theta_2}\\)")
}
cat(" chosen within this run of the application. The x-axis represents the parameter’s potential values, and the y-axis indicates their relative probability as derived from the posterior density. The density is computed using underlying R functions (e.g., bayestestR::eti() and associated Bayesian sampling methods) that summarize the results of the posterior simulations or analytical calculations. The highlighted Credible Interval (CI), shown here as an Expected Tail Interval (ETI), differs from other intervals, such as the Highest Density Interval (HDI), by including values from the tails of the distribution rather than strictly focusing on the region of highest probability density. Examination of the distribution’s shape, the ETI’s position, and its width provides insight into the plausibility of certain parameter values and the level of uncertainty associated with them.\n")
cat("\n\nThe curve represents the probability density of the parameter values, with the shaded regions highlighting different HDI levels. The red area corresponds to the 89% HDI, which captures the majority of the distribution’s density and represents the most credible range. The pink region extends this to 95%, including slightly more of the distribution, while the green and blue regions narrow further, covering 99% and 100% of the density, respectively.")
cat("(Kruschke, John K., Doing Bayesian Data Analysis, Academic Press, 2015)")
```

```{r runtests, eval=FALSE}
# Run tests  
library('testthat')
testthat::test_dir('tests/testthat/')
```

```{r cleanenv}
# Clean environment 
rm(list=ls())
```