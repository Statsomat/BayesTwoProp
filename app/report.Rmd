---
title: "Two Proportions by Bayes"
author: 
  - Denise Welsch
  - Contributors^[Students Names]
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    latex_engine: xelatex
    toc: true
    toc_depth: 2
bibliography: ["references.bib"]
classoption: landscape
params:
  data: NA
  filename: NA
  fencoding: NA
  decimal: NA
  enc_guessed: NA
  presence_outcome: NA
  presence_exposure: NA
  outcome: NA
  exposure: NA
  dataTableInput: NA 
  exposurename: NA
  outcomename:  NA
header-includes:
   - \usepackage{xcolor}
   - \setmainfont[BoldFont=FiraSans-Bold, Extension=.otf]{FiraSans-Regular}
   - \usepackage{booktabs}
   - \usepackage{longtable}
   - \usepackage{float}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, comment='', message = FALSE, error = TRUE, warning=FALSE, fig.width=8)

# Import libraries used further below
library(knitr) # for tables
library(kableExtra) # for tables 
```


```{r getdata}
# Initialize evaluation of subsequent chunks
eval0 <- FALSE
eval <- FALSE
eval_rows <- FALSE


# Get data  
tryCatch({
  
  # Get data
  df <- params$data
  
  # Save a copy for the file containing the code 
  df_code <- df
  
  # Restrict to exposure and outcome
  vars <- c(params$outcome, params$exposure)
  df <- df[, c(params$outcome, params$exposure), drop=FALSE]
  
  # Save a copy for other purposes 
  df2 <- df
  
  # Initialize next computations
  eval0 <- TRUE

}, error=function(e) {
  
  stop(safeError("Could not get the data. "))
})

```


```{r prep, eval=eval0}
# Basic data preparation 
tryCatch({

# Drop empty rows
rowsums <- data.frame(sapply(df,is.na))
if (length(which(rowSums(rowsums) == dim(df)[2])) != 0L){
  eval_rows <- TRUE
  rows_drop <- (which(rowSums(rowsums) == dim(df)[2]))
  length_non_complete <- length(which(rowSums(rowsums) == dim(df)[2]))
  df <- df[-rows_drop, ,drop=FALSE]
}


# Initialize next computations
eval <- TRUE

}, error=function(e) {
  
  stop(safeError("Dataset cannot be prepared. "))
  
}
)
```


```{r basic, results="asis", eval=eval}
# Chunk with first page of basic information
cat("# Basic Information", fill=TRUE)

cat("Automatic statistics for the file:", fill=TRUE)
dataname <- params$filename[1]
kable(dataname, col.names = "File", linesep = '', longtable=T) 

cat("Your selection for the encoding:", fill=TRUE)
if (params$fencoding=="unknown"){
  cat("Auto")
} else {cat("UTF-8")}
cat("\\newline",fill=TRUE) 

cat("Your selection for the decimal character:", fill=TRUE)
if (params$decimal=="auto"){
  cat("Auto")
} else {cat(params$decimal)}
cat("\\newline",fill=TRUE) 
  
cat("Observations (rows with at least one non-missing value): ", fill=TRUE)
cat(dim(df)[1])
cat("\\newline",fill=TRUE) 

# Missing rows
if (exists("length_non_complete")){
  cat("Number of rows that are dropped because they contain no values (all values are missing):", length_non_complete)
  cat("\\newline",fill=TRUE) 
}

if (exists("vars")){
  cat("Name of the Outcome Variable: ", params$outcome, fill=TRUE)
  cat("\\newline",fill=TRUE) 
  cat("Name of the Exposure Variable: ", params$exposure, fill=TRUE)
}

cat("\\newline",fill=TRUE) 
cat("Presence of Outcome: ", params$presence_outcome, fill=TRUE)
cat("\\newline",fill=TRUE) 
cat("Presence of Exposure: ", params$presence_exposure, fill=TRUE)

```


\pagebreak

```{r preamble, eval=eval, results='asis'}
cat("# Preamble", fill=TRUE)
cat("The data is analyzed in this app by means of Baysian data analysis. Baysian data analysis is a branch of statistical data analysis based on two fundamental ideas: The first idea is that Baysian inference is a reallocation of credibility across possibilities, by means of the well known Bayes' theorem. The second idea is that the possibilities, over which we allocate credibility are parameter values in a meaningful mathematical model.", fill=TRUE)
cat("\\newline",fill=TRUE) 
cat("\\newline",fill=TRUE) 
cat("In Bayes' theorem, an existing knowledge about the parameter(s) under investigation (the a priori distribution, or prior for short) is combined with the new knowledge from the data ('likelihood'), resulting in a new, improved knowledge (a posteriori probability distribution).", fill=TRUE)
cat("\\newline",fill=TRUE) 
cat("\\newline",fill=TRUE) 
cat("'An important benefit of Bayesian analysis is the ability to generate estimates and credible intervals for any derived parameter. Differences, ratios, effect sizes and novel parameter combinations are directly computed from the posterior distribution. Another benefit of Bayesian analysis is computationally robust estimates of parameter values and their credible intervals. The credible intervals do not depend on large-N approximations (as confidence intervals often do in frequentist approaches), nor do credible intervals depend on which tests are intended (as confidence intervals do in frequentist approaches).' (Kruschke, John K., Bayesian Analysis Reporting Guidelines, Nature Human Behaviour, 2021)", fill=TRUE)
cat("\\newline",fill=TRUE) 
cat("\\newline",fill=TRUE) 
cat("The goal of this app is to generate Bayes estimates and credible intervals for the user selected functions of parameters.", fill=TRUE)
```

```{r descplots_title, eval=eval, results='asis'}
cat("# Descriptive Plots", fill=TRUE)

print(params$dataTableInput)
```

```{r descplots, eval=eval, dev="cairo_pdf"}
```







